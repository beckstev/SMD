{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMD Übungunszettel Nr. 7\n",
    "\n",
    "Abgabe von: __Pape, Kusurmann und Becker__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 19\n",
    "\n",
    "### Aufgabenteil a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 20\n",
    "Noch ein informativer [Link](http://www.cbcity.de/tutorial-neuronale-netze-einfach-erklaert)\n",
    "### Aufgabenteil a)\n",
    "Die _Lossfunktion_ ist ein Maß dafür wie viel Information/Wahrheit bei zum Beispiel einem Schnitt verloren geht.\n",
    "Hier bei gibt es verschiedene Defintionen für eine Lossfunktion. Allgemein soll eine Operation die Lossfunktion minimieren, also die maximale Information/Wahrheit erhalten. Aus diesem Grund wird die Lossfunktion dazu verwendet, um den z.B. den geeignetes Schnitt aus einer Vielzahl von möglichen Schnitten zu ermittelt.\n",
    "\n",
    "### Aufgabenteil b)\n",
    "Durch ausprobieren oder durch das analytische bestimmen des Minimas. \n",
    "\n",
    "### Aufgabenteil c)\n",
    "Die Aktivierungsfunktion steuert, unter Berücksichtigung des Inputs, wie aktiv das Neuron ist.\n",
    "Hierbei muss der Input auch einen bestimmten Schwellwert überschreiten, bevor das Neuro überhaupt aktiviert wird.\n",
    "Durch die Aktivierungsfunktion wird somit das erstmal schon mal Noise vom Signal getrennt? Die Aktivierungsfunktionen tragen auch zum _lernen_ des Netzwerks bei. Aktivierungsfunktion der letzten Neuronenebene muss zum gewünschten Output passen.\n",
    "Beispiele:\n",
    "- lineare Funktion\n",
    "- Sigmoid Funktion\n",
    "- Leaky ReLU\n",
    "\n",
    "### Aufgabenteil d)\n",
    "Man verwendete linerare Transformationen $f=\\mathbf{W}x_i +  b$, um Daten zu klassifizieren. \n",
    "Hierbei ist $\\mathbf{W}\\in \\mathbb{R}^{N\\times M}$ die Dimensionalität der Matrix, gegeben durch die Anzahl der Eingangsneuronen $N$ und der Ausgangsneuronen $M$. Somit sind _Neuronen_ nichts anderes als die Dimensionalität der lineraten Transformationen. \n",
    "\n",
    "\n",
    "### Aufgabenteil e)\n",
    "In der Bilderkennung werden Neuronalenetzwerke verwendet, weil hier die hohe Dimensionalität des Eingangssignals\n",
    "verarbeitet und reduziert werden kann.\n",
    "\n",
    "Aber auch bei der Klassufizeriung von Datenpunkte, da diese beliebege dimensionale Fitfunktionen annehmen können und somit Daten geschickt transformieren und dann fitten. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
