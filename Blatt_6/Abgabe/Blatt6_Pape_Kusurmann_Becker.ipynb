{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blatt 06\n",
    "\n",
    "Abgabe von: __Pape, Kusurmann und Becker__\n",
    "\n",
    "## ___Damit der Code durchläuft muss die `NeutrinoM.hdf5` Datei in dem Ordner des Notebooks vorliegen.___\n",
    "\n",
    "### Aufgabe 17: _Datenaufbereitung_\n",
    "\n",
    "### a.)\n",
    "__Frage:__ Wie sollten nicht-numerische Datentypen wie beispielsweise Strings vor der Analyse\n",
    "behandelt werden müssen?\n",
    "\n",
    "__Antwort:__ Die zu analysierenden Daten müssen in eine statistisch auswertbare Darstellung gebracht werden. Dafür könnten beispielsweise Attribute wie die Stringlänge ausgewertet werden. Angepasst an das Problem muss Vorwissen (_educatet guesses_) in die ausgewählten Attribute gesteckt werden.\n",
    "\n",
    "### b.)\n",
    "__Frage:__ Kann es hilfreich sein Attribute zu normieren? Wenn ja, wieso?\n",
    "\n",
    "__Antwort:__ Eine Normierung der Daten kann die Zuordnung eines neuen Elements zu einer aus den Attributen abgeleiteten Gruppe erleichtern.\n",
    "Betrachtet man das Beispiel aus der Vorlesung mit der Zuordnung von Texten zu Atheisten und Gläubigen.\n",
    "Wir nehmen an, dass Attribute gefunden wurden, die beide Klassen gut voneinander trennt. Falls unser Testdatensatz aus sehr vielen Beiträgen von Gläubigen, aber nur wenigen Beiträgen von Atheisten besteht, ist die Zuordnung eines neuen Textes zu einer der beiden Gruppen leichter, wenn mit normierten Attributen gearbeitet wird. Darüberhinaus ist es z.B bei dem KNN-Algorithmus sinnvoll Attribute zu normieren, da so das Abstandsmaß die Attribute gleich gewichtet (vgl. `Aufgabe 15 a.)`.\n",
    "\n",
    "### c.)\n",
    "__Frage:__ Wie kann mit Lücken in den Daten oder NaNs und Infs verfahren werden?\n",
    "\n",
    "__Antwort:__ Lücken, NaNs oder Infs werden aus dem Datensatz gelöscht.\n",
    "\n",
    "### d.)\n",
    "__Frage:__ Was ist beim Zusammenführen von Datensätzen zu beachten?\n",
    "\n",
    "__Antwort:__ Die Datensätze müssen die selben Attribute besitzen. Falls man normierte Datensätze zusammenführt, muss nach dem Zusammenführen der neue Datensatz erneut normieren.\n",
    "Die Daten der verschiedenen Datensätze sollten gelabelt sein, damit man diese im Nachhinein noch unterscheiden kann.\n",
    "\n",
    "### e.)\n",
    "__Frage:__ Welche Attribute sollten vor dem Trainieren des Klassifizierers aus dem Datensatz\n",
    "entfernt werden? Wie kann dabei eine Reduktion redundanter Informationen erreicht werden? Was muss speziell bei simulationsbasierten Methoden berücksichtigt\n",
    "werden?\n",
    "\n",
    "__Antwort:__ Gleichmäßig verteilte Datenpunkte eines Attributs sollten vernachlässigt werden, da sie keinen Informationgewinn enthalten.\n",
    "Mit Hilfe der `PCA` kann die Dimensionalität des Datensatzes verringert werden, da eine Vielzahl statistischer Variablen durch eine geringere Zahl möglichst aussagekräftiger Linearkombination genähert wird.\n",
    "Speziell mit simulationsbasierten Methoden muss berücksichtigt werden, dass nicht die Monte-Carlo Wahrheit in den Datensatz einfließt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 15: _k-NN Klassifikation_\n",
    "\n",
    "#### a.)\n",
    "\n",
    "__Frage:__ Worauf müssen Sie bei einem k-NN-Algorithmus achten, wenn die Attribute sich\n",
    "stark in ihren Größenordnungen unterscheiden?\n",
    "\n",
    "__Antwort:__ Der Radius nach dem nächste Nachbarn klassifiziert werden muss auf die Größenskala der Attribute angepasst werden.\n",
    "\n",
    "#### b.)\n",
    "\n",
    "__Frage:__ Warum bezeichnet man den k-NN als sogenannten _lazy learner_? Wie sind die\n",
    "Laufzeiten für Lern- und Anwendungs-Phase? Wie sind sie im Vergleich zu anderen\n",
    "Algorithmen wie bspw. einer SVM?\n",
    "\n",
    "__Antwort:__ Der k-NN Klassifikator wird als _leazy learner_ bezeichnet, da die Modellbildung erst zur Zeit der Abfrage geschieht (Quelle: https://de.wikipedia.org/wiki/Lazy_learning).\n",
    "Die Laufzeit der Anwendungszeit ist viel größer als die Lerzeit, da für alle zu testenden Datenpunkte die Abfrage der nächsten Nachbarn gemacht werden muss.\n",
    "Der SVM-Algorithmus ist für hochdimensionale Datensätze schneller, als der k-NN Klassifikator\n",
    "Allgemein ist die Laufzeit der Anwendungsphase für _leazy learner_ länger als für sogenannte _eager learner_.\n",
    "\n",
    "#### c.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code aus der beiliegenden `class_structure.py` mit eingefügtem Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    '''KNN Classifier.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    k : int\n",
    "        Number of neighbors to consider.\n",
    "    '''\n",
    "    def __init__(self, k):\n",
    "        '''Initialization.\n",
    "        Parameters are stored as member variables/attributes.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int\n",
    "            Number of neighbors to consider.\n",
    "        '''\n",
    "        self.k = k\n",
    "        '''\n",
    "        Store training data X and label y in class object.\n",
    "        '''\n",
    "        self.training_data_X = None\n",
    "        self.training_data_y = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''Fit routine.\n",
    "        Training data is stored within object.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape=(n_samples, n_attributes)\n",
    "            Training data.\n",
    "        y : numpy.array shape=(n_samples)\n",
    "            Training labels.\n",
    "        '''\n",
    "        self.training_data_X = X\n",
    "        self.training_data_y = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''Prediction routine.\n",
    "        Predict class association of each sample of X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape=(n_samples, n_attributes)\n",
    "            Data to classify.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        prediction : numpy.array, shape=(n_samples)\n",
    "            Predictions, containing the predicted label of each sample.\n",
    "        -------\n",
    "        dist findet den Abstand zwischen jedem Datenpunkt\n",
    "        aus dem Trainingsdatensatz und einem Datenpunkt\n",
    "        aus dem Testdatansatz. Dies wird iterativ für\n",
    "        jeden Datenpunkt aus dem Testdatensatz bestimmt.\n",
    "        '''\n",
    "        \n",
    "        dist = [np.sqrt((j - self.training_data_X[0])**2\n",
    "                        + (k - self.training_data_X[1])**2\n",
    "                        + (l - self.training_data_X[2])**2)\n",
    "                for j, k, l in zip(X[0], X[1], X[2])]\n",
    "        \n",
    "        '''\n",
    "        label_trainig_data enthält die label der 10 nächsten\n",
    "        Nachbarn des Trainigsdaten zu jedem Testdatenpunkt \n",
    "        '''\n",
    "        label_training_data = np.argsort(dist)[:, :self.k]\n",
    "        \n",
    "        label_test_data = []\n",
    "\n",
    "        for n in range(len(X[0])):\n",
    "            # Abspeichern der 10 label der nächsten Nachbarn für den n-ten Datenpunkt.\n",
    "            label_buffer = self.training_data_y[label_training_data[n, :]]\n",
    "            \n",
    "            #  Bestimmen, ob mehr Nachbarn Untergrund oder Signal sind.\n",
    "            if len(label_buffer[label_buffer==0]) >= len(label_buffer[label_buffer==1]):\n",
    "                label_test_data.append(0)\n",
    "            elif len(label_buffer[label_buffer==1]) > len(label_buffer[label_buffer==0]):\n",
    "                label_test_data.append(1)\n",
    "        return np.array(label_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.)\n",
    "\n",
    "Einlesen der Daten aud der `NeutrinoMC.hdf5` Datei.\n",
    "Auf die Signale wird die Acceptance Mask angewendet, sodass nur Daten verwendet werden, die vom Detektor registriert wurden.\n",
    "\n",
    "$k = 10$ sollte nach Aufgabenstellung gewählt werden. Da $k$ gerade ist kann es vorkommen, dass genauso viele NN Signal wie Untergrund sind. Falls dieser Fall eintrifft ist der Algorithmus so eingestellt, dass er diesen Testpunkt als Untergrund erkennt, damit die Reinheit möglichst groß gehalten wird. Allgemein ist es besser ein ungerades $k$ zu wählen, damit dieses Problem umgangen wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = pd.read_hdf('NeutrinoMC.hdf5', 'Signal')\n",
    "\n",
    "signal = signal[signal.AcceptanceMask]\n",
    "\n",
    "background = pd.read_hdf('NeutrinoMC.hdf5', 'Background')\n",
    "\n",
    "k = KNN(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erzeugen von 5000 zufällig aus dem `.hdf5` gewählten Trainingsdatenpunkten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_training = 5000\n",
    "\n",
    "training_signal = signal.sample(N_training)\n",
    "\n",
    "training_background = background.sample(N_training)\n",
    "\n",
    "training_data = pd.DataFrame({\n",
    "    'x' : training_signal['x'].append(training_background['x']),\n",
    "    'y' : training_signal['y'].append(training_background['y']),\n",
    "    'NumberOfHits' : training_signal['NumberOfHits'].append(\n",
    "        training_background['NumberOfHits'])\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Label wurden so gewählt, dass das Label 1 ein Signal und 0 ein Untergrundereignis repräsentiert.\n",
    "\n",
    "Die `fit`-Methode wird aufgerufen, damit die Trainingsdaten in das Klassenelement $k$ gespeichert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label = np.append(np.ones(N_training), np.zeros(N_training))\n",
    "k.fit(X=[training_data['x'],\n",
    "         training_data['y'],\n",
    "         training_data['NumberOfHits']],\n",
    "      y=training_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erzeugen von 10.000 Testsignalen und 20.000 Testuntergrundsignalen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_test = 10000\n",
    "\n",
    "test_signal = signal.sample(N_test)\n",
    "\n",
    "test_background = background.sample(2 * N_test)\n",
    "\n",
    "test_data = pd.DataFrame({\n",
    "    'x' : test_signal['x'].append(test_background['x']),\n",
    "    'y' : test_signal['y'].append(test_background['y']),\n",
    "    'NumberOfHits' : test_signal['NumberOfHits'].append(\n",
    "        test_background['NumberOfHits'])\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predict`-Methode bestimmt die mit dem KNN-Algorithmus ermittelten Label der Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = k.predict(X=[test_data['x'],\n",
    "                          test_data['y'],\n",
    "                          test_data['NumberOfHits']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testen welche Signale und welche Hintergrundereignisse richtig zugeordnet wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "signal_test = np.array([test_data['x'][test_label == 1],\n",
    "                        test_data['y'][test_label == 1],\n",
    "                        test_data['NumberOfHits'][test_label == 1]])\n",
    "background_test = np.array([test_data['x'][test_label == 0],\n",
    "                            test_data['y'][test_label == 0],\n",
    "                            test_data['NumberOfHits'][test_label == 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestimmen der Effizienz, Reinheit und Signifikanz.\n",
    "Die Signifikanz wird berechnet mit\n",
    "$$S = \\frac{tp}{\\sqrt{tp + fp}}.$$\n",
    "\n",
    "`true_test_label` enthält die richtigen Label der Testdaten, da diese aus der ausgelesenen `.hdf5` Datei bekannt waren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_test_label = np.append(np.ones(N_test), np.zeros(2 * N_test))\n",
    "\n",
    "tp = len(test_label[(true_test_label==1) & (test_label==1)])\n",
    "fn = len(test_label[(true_test_label==1) & (test_label==0)])\n",
    "fp = len(test_label[(true_test_label==0) & (test_label==1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestimmen der `Effizienz`, der `Reinheit` und der `Signifikanz`.\n",
    "Könnt ihr in der Übung nochmal erklären was die `Signifikanz` über der verwendeten Algorithmus oder die Daten aussagt?\n",
    "\n",
    "In der Vorlesung wurde der Begriff `Signifikanz` nicht eingeführt. Wir haben jetzt die Definition von `Blatt 04` verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effizienz = tp / (tp + fn)\n",
    "reinheit = tp / (tp + fp)\n",
    "signifikanz = tp / np.sqrt(tp + fp)\n",
    "\n",
    "print(f'Effizienz = {effizienz}\\nReinheit = {reinheit}\\nSignifikanz = {signifikanz}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e.)\n",
    "Was ändert sich, wenn Sie log10(AnzahlHits) statt AnzahlHits nutzen?\n",
    "\n",
    "Erstellen eines DataFrames mit logarithmierten dritten Attribut.\n",
    "Im Verlauf des Codes wird analog zu Aufgabenteil `d.)` vorgegangen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_log_hits = pd.DataFrame({\n",
    "    'x' : training_signal['x'].append(training_background['x']),\n",
    "    'y' : training_signal['y'].append(training_background['y']),\n",
    "    'log10(NumberOfHits)' : np.log10(training_signal['NumberOfHits']).append(\n",
    "        np.log10(training_background['NumberOfHits']))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.fit(X=[training_data_log_hits['x'],\n",
    "         training_data_log_hits['y'],\n",
    "         training_data_log_hits['log10(NumberOfHits)']],\n",
    "      y=training_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_log_hits = pd.DataFrame({\n",
    "    'x' : test_signal['x'].append(test_background['x']),\n",
    "    'y' : test_signal['y'].append(test_background['y']),\n",
    "    'log10(NumberOfHits)' : np.log10(test_signal['NumberOfHits']).append(\n",
    "        np.log10(test_background['NumberOfHits']))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_label_log_hits = k.predict(X=[test_data_log_hits['x'],\n",
    "                                   test_data_log_hits['y'],\n",
    "                                   test_data_log_hits['log10(NumberOfHits)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_test_log_hits = np.array([test_data_log_hits['x'][test_label_log_hits == 1],\n",
    "                                 test_data_log_hits['y'][test_label_log_hits == 1],\n",
    "                                 test_data_log_hits['log10(NumberOfHits)'][test_label_log_hits == 1]])\n",
    "background_test_log_hits = np.array([test_data_log_hits['x'][test_label_log_hits == 0],\n",
    "                                     test_data_log_hits['y'][test_label_log_hits == 0],\n",
    "                                     test_data_log_hits['log10(NumberOfHits)'][test_label_log_hits == 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_log = len(true_test_label[(true_test_label==1) & (test_label_log_hits==1)])\n",
    "fn_log = len(true_test_label[(true_test_label==1) & (test_label_log_hits==0)])\n",
    "fp_log = len(true_test_label[(true_test_label==0) & (test_label_log_hits==1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effizienz_log = tp_log / (tp_log + fn_log)\n",
    "reinheit_log = tp_log / (tp_log + fp_log)\n",
    "signifikanz_log = tp_log / np.sqrt(tp_log + fp_log)\n",
    "\n",
    "print(f'Effizienz = {effizienz_log}\\nReinheit = {reinheit_log}\\nSignifikanz = {signifikanz_log}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle drei Werte sind größer als bei dem Test ohne logarithmiertes drittes Attribut.\n",
    "\n",
    "In den Plotts am Ende der Aufgabe sieht man auch, dass das Signal deutlich weniger _verschmiert_ ist als\n",
    "in dem Plot der vorigen Daten aus `d.)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f.)\n",
    "Was ändert sich, wenn Sie k = 20 statt k = 10 verwenden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_20 = KNN(20)\n",
    "k_20.fit(X=[training_data['x'],\n",
    "            training_data['y'],\n",
    "            training_data['NumberOfHits']],\n",
    "         y=training_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_20 = k_20.predict(X=[test_data['x'],\n",
    "                                test_data['y'],\n",
    "                                test_data['NumberOfHits']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_test_20 = np.array([test_data['x'][test_label_20 == 1],\n",
    "                           test_data['y'][test_label_20 == 1],\n",
    "                           test_data['NumberOfHits'][test_label_20 == 1]])\n",
    "background_test_20 = np.array([test_data['x'][test_label_20 == 0],\n",
    "                               test_data['y'][test_label_20 == 0],\n",
    "                               test_data['NumberOfHits'][test_label_20 == 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_20 = len(true_test_label[(true_test_label==1) & (test_label_20==1)])\n",
    "fn_20 = len(true_test_label[(true_test_label==1) & (test_label_20==0)])\n",
    "fp_20 = len(true_test_label[(true_test_label==0) & (test_label_20==1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effizienz_20 = tp_20 / (tp_20 + fn_20)\n",
    "reinheit_20 = tp_20 / (tp_20 + fp_20)\n",
    "signifikanz_20 = tp_20 / np.sqrt(tp_20 + fp_20)\n",
    "\n",
    "print(f'Effizienz = {effizienz_20}\\nReinheit = {reinheit_20}\\nSignifikanz = {signifikanz_20}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die drei Werte sind alle schlechter als bei den Werten aus Aufgabenteil `d.)`.\n",
    "Dies sieht man auch in dem unteren Plot zu Aufgabenteil `f.)`, da das Signal _verschmierter_ in dem Untergrund ist als bei den anderen Aufgabenteilen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotten der Ergebnisse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,15])\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "\n",
    "plt.scatter(test_data['x'][N_test:], test_data['y'][N_test:], s=5, alpha=0.3, label='True Background', color='C1')\n",
    "plt.scatter(test_data['x'][:N_test], test_data['y'][:N_test], s=5, alpha=0.5, label='True Signal', color='C0')\n",
    "\n",
    "plt.legend(fontsize='large', loc='upper left')\n",
    "plt.xlabel(r'$x$-Achse')\n",
    "plt.ylabel(r'$y$-Achse')\n",
    "\n",
    "##########################################\n",
    "plt.subplot(2,2,2)\n",
    "\n",
    "plt.scatter(background_test[0], background_test[1], s=5, alpha=0.2, color='C1', label='Test Background')\n",
    "plt.scatter(signal_test[0], signal_test[1], s=5, alpha=0.4, color='C2', label='Test Signal')\n",
    "\n",
    "plt.xlabel(r'$x$-Achse')\n",
    "plt.ylabel(r'$y$-Achse')\n",
    "plt.legend(fontsize='large')\n",
    "\n",
    "##########################################\n",
    "plt.subplot(2,2,3)\n",
    "\n",
    "plt.scatter(background_test_log_hits[0], background_test_log_hits[1], s=5, alpha=0.5, color='C1', label=r'Test Background$_{log10}$')\n",
    "plt.scatter(test_data['x'][:N_test], test_data['y'][:N_test], s=5, alpha=0.5, color='C0', label=r'Signal$_{log10}$')\n",
    "plt.scatter(signal_test_log_hits[0], signal_test_log_hits[1], s=5, alpha=0.5, color='C2', label=r'Test Signal$_{log10}$')\n",
    "\n",
    "plt.legend(fontsize='large')\n",
    "plt.xlabel(r'$x$-Achse')\n",
    "plt.ylabel(r'$y$-Achse')\n",
    "\n",
    "##########################################\n",
    "plt.subplot(2,2,4)\n",
    "\n",
    "plt.scatter(background_test_20[0], background_test_20[1], s=5, alpha=0.5, color='C1', label='Test Background k = 20')\n",
    "plt.scatter(signal_test_20[0], signal_test_20[1], s=5, alpha=0.5, color='C2', label='Test Signal k = 20')\n",
    "\n",
    "plt.legend(fontsize='large')\n",
    "plt.xlabel(r'$x$-Achse')\n",
    "plt.ylabel(r'$y$-Achse')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Plot links oben zeigt das wahre Signal aus der `.hdf5` Datei an.\n",
    "\n",
    "Der Plot rechts oben zeigt das rekonstruierte Signal aus Aufgabenteil `d.)` an.\n",
    "\n",
    "Der Plot unten links zeigt die Ergebnisse von Aufgabenteil `e.)`. Im blau sind die wahren Testsignale mit logarithmierter Hit Anzahl dargestellt.\n",
    "\n",
    "Der Plot unten rechts zeigt das mit $k = 20$ rekonstruierte Signal aus Aufgabenteil `f.)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 16: _Binärer Entscheidungsbaum: Die erste Entscheidung_\n",
    "\n",
    "Angaben vom Übungsblatt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [29, 26, 28, 21, 20, 18, 17, 22, 20, 24, 24, 22, 27, 22]\n",
    "vorhersage = [2, 2, 1, 0, 0, 0, 1, 2, 2, 0, 2, 1, 1, 0]\n",
    "luftfeuchtigkeit = [80, 90, 70, 90, 80, 70, 65, 90, 70, 80, 70, 90, 75, 80]\n",
    "wind = [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1]\n",
    "fußball = [0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame()\n",
    "df_test['temp'] = temp\n",
    "df_test['vor'] = vorhersage\n",
    "df_test['luftf'] = luftfeuchtigkeit\n",
    "df_test['wind'] = wind\n",
    "df_test['fußball'] = fußball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropie(S, S_c):\n",
    "    return - S_c / S * np.log2(S_c / S)\n",
    "\n",
    "def gain(S, S_c):\n",
    "    return (entropie(len(S), len(S[S == True]))\n",
    "            + entropie(len(S), len(S[S == False]))\n",
    "            - sum(S_c == True) / len(S) *\n",
    "            (entropie(sum(S_c == True), sum((S_c == True) & (S == True)))\n",
    "            + entropie(sum(S_c == True), sum((S_c == True) & (S == False))))\n",
    "            - sum(S_c == False) / len(S) *\n",
    "            (entropie(sum(S_c == False), sum((S_c == False) & (S == False)))\n",
    "            + entropie(sum(S_c == False), sum((S_c == False) & (S == True)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.)\n",
    "Bestimmen der Entropie der Wurzel.\n",
    "\n",
    "Die Entropie wird nach der folgenden Formel bestimmt:\n",
    "\n",
    "$$H(S) = - \\sum_{c=1}^{|C|}p_c\\log_2(p_c).$$\n",
    "\n",
    "Dabei ist $S$ der Datensatz, $|C|$ die Anzahl der Kategorien und $p_c$ der Anteil er Instanz in S, die Kategorie c angehört.\n",
    "(vgl. http://www.coli.uni-saarland.de/courses/mathe3/SS12/Vorlesungen/decisiontree.pdf, Folie 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_root = (entropie(len(df_test.fußball), len(df_test.fußball[df_test.fußball == True]))\n",
    "          + entropie(len(df_test.fußball), len(df_test.fußball[df_test.fußball == False])))\n",
    "print(f'Entropie der Wurzel: {S_root:.5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.)\n",
    "Ermitteln des Informationszuwachses durch das Attribut `Wind`.\n",
    "\n",
    "Die Funktion `gain` wird wie folgt konstruiert:\n",
    "\n",
    "$$gain(S,A) = H(S) - \\sum_{v\\in A}\\frac{|S_v|}{|S|} H(S_v).$$\n",
    "\n",
    "(vgl. http://www.coli.uni-saarland.de/courses/mathe3/SS12/Vorlesungen/decisiontree.pdf Folie 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_wind = gain(df_test.fußball, df_test.wind)\n",
    "\n",
    "print(f'Informationsentropie des Attributes Wind: {gain_wind:.5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.) \n",
    "Ermitteln des Informationszuwachses durch verschiedene Schnitte der übrigen Attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=2, criterion='entropy')\n",
    "clf.fit(np.array(wind).reshape(-1, 1), fußball)\n",
    "tree.export_graphviz(clf,out_file='test.dot') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(end_state, test_state):\n",
    "    n = sum(end_state)\n",
    "    H = []\n",
    "    for i in test_state:\n",
    "        H_i = []\n",
    "        for j in end_state:\n",
    "            H_i.append( -j/n *  np.log2(j/i))\n",
    "           \n",
    "        H.append(sum(H_i))\n",
    "    return sum(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Fußball\n",
    "n_p = sum(df_test.fußball)\n",
    "# False Fußball\n",
    "n_pn = sum(df_test.fußball == False)\n",
    "\n",
    "# negativ weather forecast\n",
    "n_s = sum(df_test.vor == 2)\n",
    "# neutral weather forecast\n",
    "n_n = sum(df_test.vor == 1)\n",
    "# positiv weather forecast\n",
    "n_g = sum(df_test.vor == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_forecast = H([n_p, n_pn], [n_s, n_n, n_g])\n",
    "\n",
    "information_gain_forecast = S_root - H_forecast\n",
    "\n",
    "print('Der Informationsgehalt bei einem Schnitt',\n",
    "       f'auf dem Attribut Wettervorhersage durchgeführt \\n wird, liegt bei {information_gain_forecast:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luftfeuchtigkeit x >= 90 %\n",
    "n_90 = sum(df_test.luftf >= 90)\n",
    "# Luftfeuchtigkeit 90 > x >= 80 %\n",
    "n_80 = sum((df_test.luftf < 90) & (df_test.luftf >= 80))\n",
    "# Luftfeuchtigkeit 80 > x >= 70%\n",
    "n_70 = sum((df_test.luftf < 80) & (df_test.luftf >= 70))\n",
    "# Luftfeuchtigkeit 70 >x >= 60%\n",
    "n_60 = sum((df_test.luftf < 70) & (df_test.luftf >= 60))\n",
    "\n",
    "H_humanity = H([n_p, n_pn], [n_90, n_80, n_70, n_60])\n",
    "\n",
    "inforamtion_gain_humanity = S_root - H_humanity\n",
    "\n",
    "print('Der Informationsgehalt bei einem Schnitt',\n",
    "       f'auf dem Attribut Luftfeuchtigkeit durchgeführt \\n wird, liegt bei {inforamtion_gain_humanity:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d.)\n",
    "\n",
    "Die Wettervorhersage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 18: _Naive Bayes: Fußball_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.)\n",
    "\n",
    "Die bedingte Wahrscheinlichkeit ist definiert als\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(A\\cap B)}{P(B)}.\n",
    "$$\n",
    "Es gilt \n",
    "\n",
    "$$\n",
    "P(A|B)P(B) = P(A\\cap B) = P(B\\cap A) = P(B|A)P(A)\\quad \\mathrm{q.e.d.}\n",
    "$$\n",
    "Damit ist der __Satz von Bayes__ bewiesen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.)\n",
    "Wir möchten wissen: Wie hoch die Wahrscheinlichkeit ist, dass wir, bei den gegebenen Wetterbedingungen $W$, Fußball spielen $F$ gehen.\n",
    "Präzise erfasst wird diese Fragestellung durch:\n",
    "$$\n",
    "P(F|W) = \\frac{P(F)}{P(W)}P(W|F).\n",
    "$$\n",
    "Hierbei gibt $P(F)$ die Wahrscheinlichkeit an das wir überhaupt Fußball spielen gehen und $P(W)$ die Wahrschelichkeit die angegebene Wetterkonfiguration zuerhalten.\n",
    "\n",
    "Wenn $n$ die Gesamtzahl unserer Messungen ist und $n_F$ angibt, wie oft wir Fußball spielen waren. \n",
    "So gilt:\n",
    "$$\n",
    "P(F)= \\frac{n_F}{n} = \\frac{9}{14}\n",
    "$$\n",
    "Wenn $n_{windig}$ die Anzahl die Tage ist an den der Wind stark war, $n_{high-humidity}$ die Anzahl der Tage mit einer hohen Luftfeutigkeit, $n_{cold}$ die Anzahl der Tage wo es kalt ist, $n_{sunny}$ die Tage mit sonnigen Aussichten, dann kann $P(W)$ geschrieben werden als:\n",
    "$$\n",
    "P(W)=\\frac{n_{windy}\\cdot n_{high-humidity} \\cdot n_{cold} \\cdot n_{sunny}} {n^4} = \\frac{6\\cdot7\\cdot6\\cdot3}{14^4}=\\frac{756}{14^4}\n",
    "$$\n",
    "Nach Voraussetzung gilt \n",
    "$$\n",
    "P(W|F)=\\Pi_i P(x_i|F).\n",
    "$$\n",
    "P(W|F) gibt an wie Wahrscheinlichkeit ist dieses Wetter zu finden, wenn man Fußball spielen geht.\n",
    "\n",
    "$$\n",
    "P(W|F)=P(windy|F)\\cdot P(high-humidity|F)\\cdot P(cold|F)\\cdot P(sunny|F) = \\frac{3}{9}\\cdot\\frac{3}{9}\\cdot\\frac{3}{9}\\cdot\\frac{2}{9}=\\frac{54}{6561}=\\frac{2}{243}\n",
    "$$\n",
    "Somit ist $P(F|W)$, also die Wahrscheinlichkeit Fußball spielen zu gehen, gleich\n",
    "\n",
    "$$\n",
    "P(F|W) =  \\frac{P(F)}{P(W)}P(W|F) \\approx 0.27 \\rightarrow 27\\%\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.)\n",
    "Das Problem hier ist, dass wir noch nie Fußball spielen gegenagen sind als es heiß war, somit können wir keine wirkliche Aussage über $P(F|W)$ treffen. Stattdessen können wir berechnen, wie wahrscheinlich es ist das wir nicht Fußball spielen $NF$ gehen, bei der gegebenen Wetterkonfiguration. \n",
    "$$\n",
    "P(NF|W) = \\frac{P(NF)}{P(W)}P(W|NF)\n",
    "$$\n",
    "mit \n",
    "$$\\begin{aligned}\n",
    "P(NF)&= \\frac{n_{NF}}{n} = \\frac{5}{14},\\\\\n",
    "P(W)&=\\frac{n_{not-windy}\\cdot n_{high-humidity} \\cdot n_{hot} \\cdot n_{sunny}}{n^4} = \\frac{8\\cdot7\\cdot1\\cdot3}{14^4}=\\frac{168}{14^4}, \\\\\n",
    "P(W|NF)&=\\Pi_i P(x_i|NF) = P(not-windy|NF)\\cdot P(high-humidity|NF)\\cdot P(hot|NF)\\cdot P(sunny|NF) = \\frac{2\\cdot4\\cdot1\\cdot1}{5^4}=\\frac{8}{5^4}\n",
    "\\end{aligned}$$\n",
    "ergibt sich\n",
    " \n",
    "$$\n",
    "P(NF|W) = \\frac{P(NF)}{P(W)} P(W|NF) \\approx 1 \\quad \\text{Hier kommt ein Wert größer knapp größer 1 raus, dass kann eigentlich nicht so sein!} \n",
    "$$\n",
    "Dann ist \n",
    "$$\n",
    "P(F|W) = 1 - P(NF|W) \\approx 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
